/**
 * LLM Integration for generating betting tips
 */

import { AUTOMATION_CONFIG, LLM_PROMPTS } from './config';
import { logger } from './logger';
import type { DailyTipsPayload } from '../../src/lib/types';
import { DailyTipsPayloadSchema } from '../../src/lib/schemas';

export interface LLMProvider {
  generateTips(): Promise<DailyTipsPayload>;
}

export class OpenAIProvider implements LLMProvider {
  private apiKey: string;
  private baseURL: string = 'https://api.openai.com/v1';

  constructor(apiKey?: string) {
    this.apiKey = apiKey || process.env.OPENAI_API_KEY || '';
    if (!this.apiKey) {
      throw new Error('OpenAI API key not found in environment variables');
    }
  }

  async generateTips(): Promise<DailyTipsPayload> {
    logger.info('Generating tips using OpenAI with online research...');

    const researchSources = AUTOMATION_CONFIG.researchSources;
    
    try {
      const response = await fetch(`${this.baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: AUTOMATION_CONFIG.llm.model,
          messages: [
            {
              role: 'system',
              content: LLM_PROMPTS.systemPrompt
            },
            {
              role: 'user', 
              content: LLM_PROMPTS.generationPrompt(researchSources)
            }
          ],
          max_tokens: AUTOMATION_CONFIG.llm.maxTokens,
          temperature: AUTOMATION_CONFIG.llm.temperature,
          response_format: { type: 'json_object' }
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
      }

      const result = await response.json();
      const generatedContent = result.choices[0]?.message?.content;

      if (!generatedContent) {
        throw new Error('No content generated by OpenAI');
      }

      logger.info('OpenAI response received', { 
        tokens: result.usage?.total_tokens,
        model: result.model 
      });

      return this.parseAndValidateResponse(generatedContent);

    } catch (error) {
      logger.error('OpenAI API call failed:', error);
      throw error;
    }
  }



  private parseAndValidateResponse(content: string): DailyTipsPayload {
    try {
      const parsed = JSON.parse(content);
      
      // Validate against schema
      const validated = DailyTipsPayloadSchema.parse(parsed);
      
      logger.info('LLM response validated successfully', {
        tipsGenerated: validated.tips.length,
        date: validated.dateISO
      });

      return validated;

    } catch (error) {
      logger.error('Failed to parse/validate LLM response:', error);
      logger.error('Raw LLM content:', content);
      throw new Error(`Invalid LLM response format: ${error}`);
    }
  }
}

export class AnthropicProvider implements LLMProvider {
  private apiKey: string;
  private baseURL: string = 'https://api.anthropic.com/v1';

  constructor(apiKey?: string) {
    this.apiKey = apiKey || process.env.ANTHROPIC_API_KEY || '';
    if (!this.apiKey) {
      throw new Error('Anthropic API key not found in environment variables');
    }
  }

  async generateTips(): Promise<DailyTipsPayload> {
    logger.info('Generating tips using Anthropic Claude with online research...');

    const researchSources = AUTOMATION_CONFIG.researchSources;
    
    try {
      const response = await fetch(`${this.baseURL}/messages`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'x-api-key': this.apiKey,
          'anthropic-version': '2023-06-01'
        },
        body: JSON.stringify({
          model: 'claude-3-haiku-20240307', // Cost-effective model
          max_tokens: AUTOMATION_CONFIG.llm.maxTokens,
          temperature: AUTOMATION_CONFIG.llm.temperature,
          system: LLM_PROMPTS.systemPrompt,
          messages: [
            {
              role: 'user',
              content: LLM_PROMPTS.generationPrompt(researchSources)
            }
          ]
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Anthropic API error: ${response.status} - ${errorText}`);
      }

      const result = await response.json();
      const generatedContent = result.content[0]?.text;

      if (!generatedContent) {
        throw new Error('No content generated by Anthropic');
      }

      logger.info('Anthropic response received', { 
        tokens: result.usage?.input_tokens + result.usage?.output_tokens 
      });

      return this.parseAndValidateResponse(generatedContent);

    } catch (error) {
      logger.error('Anthropic API call failed:', error);
      throw error;
    }
  }



  private parseAndValidateResponse(content: string): DailyTipsPayload {
    try {
      // Extract JSON from markdown if needed
      const jsonMatch = content.match(/```json\n?(.*?)\n?```/s);
      const jsonContent = jsonMatch ? jsonMatch[1] : content;
      
      const parsed = JSON.parse(jsonContent);
      const validated = DailyTipsPayloadSchema.parse(parsed);
      
      logger.info('LLM response validated successfully', {
        tipsGenerated: validated.tips.length,
        date: validated.dateISO
      });

      return validated;

    } catch (error) {
      logger.error('Failed to parse/validate LLM response:', error);
      logger.error('Raw LLM content:', content);
      throw new Error(`Invalid LLM response format: ${error}`);
    }
  }
}

export class LLMManager {
  private provider: LLMProvider;

  constructor() {
    const config = AUTOMATION_CONFIG.llm;
    
    switch (config.provider) {
      case 'openai':
        this.provider = new OpenAIProvider();
        break;
      case 'anthropic':
        this.provider = new AnthropicProvider();
        break;
      default:
        throw new Error(`Unsupported LLM provider: ${config.provider}`);
    }

    logger.info(`LLM Manager initialized with provider: ${config.provider}`);
  }

  async generateDailyTips(): Promise<DailyTipsPayload> {
    const maxRetries = AUTOMATION_CONFIG.schedule.retryAttempts;
    let lastError: Error | null = null;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        logger.info(`LLM generation attempt ${attempt}/${maxRetries}`);
        
        const result = await this.provider.generateTips();
        
        // Additional validation
        this.validateGeneratedTips(result);
        
        logger.info('Daily tips generated successfully', {
          attempt,
          tipsCount: result.tips.length,
          date: result.dateISO
        });

        return result;

      } catch (error) {
        lastError = error as Error;
        logger.warn(`LLM generation attempt ${attempt} failed:`, error);
        
        if (attempt < maxRetries) {
          const delayMs = AUTOMATION_CONFIG.schedule.retryDelayMinutes * 60 * 1000;
          logger.info(`Retrying in ${AUTOMATION_CONFIG.schedule.retryDelayMinutes} minutes...`);
          await new Promise(resolve => setTimeout(resolve, delayMs));
        }
      }
    }

    throw new Error(`Failed to generate tips after ${maxRetries} attempts. Last error: ${lastError?.message}`);
  }

  private validateGeneratedTips(payload: DailyTipsPayload): void {
    const config = AUTOMATION_CONFIG.generation;
    
    // Check tip count
    if (payload.tips.length !== config.tipsPerDay) {
      throw new Error(`Expected ${config.tipsPerDay} tips, got ${payload.tips.length}`);
    }

    // Check risk distribution
    const risks = payload.tips.map(tip => tip.risk);
    if (!config.riskDistribution.every(risk => risks.includes(risk))) {
      throw new Error(`Missing risk levels. Expected: ${config.riskDistribution.join(', ')}, Got: ${risks.join(', ')}`);
    }

    // Check odds range
    for (const tip of payload.tips) {
      for (const leg of tip.legs) {
        if (leg.avgOdds < config.minOdds || leg.avgOdds > config.maxOdds) {
          throw new Error(`Odds ${leg.avgOdds} outside allowed range ${config.minOdds}-${config.maxOdds}`);
        }
      }
    }

    logger.info('Generated tips passed all validation checks');
  }
}
